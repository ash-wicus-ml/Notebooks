{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57844c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Below we will find different types of neural network architectures that can be used to solve various problems across \n",
    "# different domains, including image processing, sequence modeling, generative modeling, and various other use cases.\n",
    "# Each of these neural network architectures has its strengths and weaknesses and each is suitable for different types \n",
    "# of tasks and data. Understanding the characteristics of each architecture is crucial for selecting the appropriate \n",
    "# model for a given problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b01963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################################################################################################\n",
    "# Feedforward Neural Network (FNN):\n",
    "\n",
    "# A Feedforward Neural Network (FNN), also known as a Multilayer Perceptron (MLP), is a type of artificial neural \n",
    "# network where connections between the nodes do not form cycles. In other words, the information flows in one direction, \n",
    "# from the input layer through one or more hidden layers to the output layer, without any loops or feedback connections.\n",
    "# So, essentially, information flows in one direction (from input to output).\n",
    "\n",
    "# Feedforward Neural Networks are commonly used for various supervised learning tasks, including:\n",
    "\n",
    "# Classification: FNNs can be used for classification tasks where the goal is to assign input data points to one of \n",
    "# several predefined categories. For example, classifying emails as spam or not spam, classifying images of digits \n",
    "# into their respective categories (0-9), or categorizing news articles into different topics.\n",
    "\n",
    "# Regression: FNNs can also be used for regression tasks where the goal is to predict a continuous numerical value \n",
    "# based on input data. For example, predicting house prices based on features such as location, size, and number of \n",
    "# bedrooms, or predicting the sales volume of a product based on various marketing factors.\n",
    "\n",
    "# Pattern Recognition: FNNs are effective for recognizing patterns in input data, making them suitable for tasks such as\n",
    "# handwriting recognition, speech recognition, and facial recognition.\n",
    "\n",
    "# Function Approximation: FNNs can approximate complex mathematical functions, making them useful for tasks such as \n",
    "# function approximation, curve fitting, and modeling complex relationships between input and output variables.\n",
    "\n",
    "\n",
    "# In the example below, we will focus on handwriting recognition, specifically handwritten numbers 1-9\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import cv2\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train.reshape((X_train.shape[0], -1)).astype('float32') / 255.0\n",
    "X_test = X_test.reshape((X_test.shape[0], -1)).astype('float32') / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(784,)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the predictions\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print some example predictions\n",
    "for i in range(10):\n",
    "    print(\"Predicted:\", predicted_labels[i])\n",
    "\n",
    "\n",
    "\n",
    "# Load the image containing the handwritten digit (the image is the number 7)\n",
    "image = cv2.imread('C:\\\\Users\\\\ryan_\\\\Desktop\\\\number_image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Resize the image to 28x28 pixels (same as MNIST images)\n",
    "image_resized = cv2.resize(image, (28, 28))\n",
    "\n",
    "# Invert the image (if necessary, depending on how the model was trained)\n",
    "image_inverted = cv2.bitwise_not(image_resized)\n",
    "\n",
    "# Flatten the image and normalize pixel values\n",
    "input_data = image_inverted.reshape((1, -1)).astype('float32') / 255.0\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(input_data)\n",
    "\n",
    "# Get the predicted label\n",
    "predicted_label = np.argmax(prediction)\n",
    "\n",
    "print(\"Predicted label:\", predicted_label)\n",
    "\n",
    "# Final Result: \n",
    "# \"Predicted label: 7\"\n",
    "\n",
    "# Yeah! The model learned what the number 7 looks like, and it corredctly predicted the the image was indeed the number 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48699a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# Recurrent Neural Network (RNN):\n",
    "\n",
    "# A Recurrent Neural Network (RNN), is a type of artificial neural network designed to handle sequential data. Unlike traditional \n",
    "# feedforward neural networks, where information flows in one direction (from input to output), RNNs have connections that form \n",
    "# directed cycles, allowing them to exhibit temporal dynamic behavior.\n",
    "\n",
    "# Here are the key components of an RNN:\n",
    "\n",
    "# Recurrent Connections: The defining feature of RNNs is the presence of recurrent connections that allow information to persist \n",
    "# over time. This means that the output of a neuron at a given time step serves as an input to the same neuron at the next time step.\n",
    "\n",
    "# Hidden State: RNNs maintain a hidden state that represents a memory of the previous time steps. This hidden state is updated at each \n",
    "# time step based on the current input and the previous hidden state.\n",
    "\n",
    "# Variable Length Sequences: RNNs can process sequences of variable length, making them suitable for tasks involving sequences like \n",
    "# time series prediction, natural language processing, speech recognition, and more.\n",
    "\n",
    "# Types of RNNs:\n",
    "#  One-to-One: Traditional feedforward neural networks where there's no sequential processing involved.\n",
    "#  One-to-Many: Takes a single input and generates a sequence of outputs (e.g., image captioning).\n",
    "#  Many-to-One: Processes a sequence of inputs and produces a single output (e.g., sentiment analysis).\n",
    "#  Many-to-Many (sequence-to-sequence): Takes a sequence of inputs and produces a sequence of outputs (e.g., machine translation).\n",
    "#  Bidirectional: Processes the input sequence in both forward and backward directions, allowing the model to capture dependencies \n",
    "#  from both past and future contexts.\n",
    "\n",
    "# Vanishing Gradient Problem: RNNs are susceptible to the vanishing gradient problem, where gradients become extremely small during \n",
    "# backpropagation, leading to difficulties in learning long-term dependencies. This limitation has led to the development of more \n",
    "# sophisticated RNN variants like Long Short-Term Memory (LSTM) networks and Gated Recurrent Units (GRUs), which are designed to \n",
    "# address this issue by introducing mechanisms to control the flow of information through the network.\n",
    "\n",
    "# In the example below, we will do a simple language translation exercise, which falls into the category of Many-to-Many (sequence-to-sequence)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Example data\n",
    "input_texts = ['hello', 'nice to meet youy', 'goodbye']\n",
    "target_texts = ['bonjour', 'ravi de vous rencontrer', 'au revoir']\n",
    "\n",
    "# Tokenization (character level)\n",
    "input_characters = sorted(set(''.join(input_texts)))\n",
    "target_characters = sorted(set(''.join(target_texts)))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "# Add start and end tokens to target characters\n",
    "start_token = '\\t'\n",
    "end_token = '\\n'\n",
    "target_characters = [start_token, end_token] + target_characters\n",
    "num_decoder_tokens = len(target_characters)\n",
    "\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
    "\n",
    "# Prepare data for training\n",
    "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "\n",
    "\n",
    "# Define the Seq2Seq model architecture\n",
    "latent_dim = 256\n",
    "\n",
    "encoder_inputs = tf.keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = tf.keras.Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=1, epochs=50)\n",
    "\n",
    "# Define encoder and decoder models for inference\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = tf.keras.Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = tf.keras.Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Function to decode sequence\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.0  # Start token\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length or find stop token\n",
    "        if sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1) and states\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "# Test the model on new input sequences\n",
    "for seq_index in range(len(input_texts)):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    \n",
    "\n",
    "# Final Result:   \n",
    "    \n",
    "# Input sentence: hello\n",
    "# Decoded sentence: onjoerrrrrrrrrrrrrrrrrrr\n",
    "\n",
    "# Input sentence: nice to meet youy\n",
    "# Decoded sentence: avi         rrrrrrrrrrrr\n",
    "\n",
    "# Input sentence: goodbye\n",
    "# Decoded sentence: onjoerrrrrrrrrrrrrrrrrrr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa9ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# Convolutional Neural Network (CNN):\n",
    "\n",
    "# A Convolutional Neural Network (CNN) is a type of deep neural network that is primarily used for tasks involving image \n",
    "# processing and computer vision. CNNs are particularly effective for tasks such as image classification, object detection, \n",
    "# image segmentation, and image generation. Here are some common applications of Convolutional Neural Networks:\n",
    "\n",
    "# Image Classification: CNNs are widely used for image classification tasks, where the goal is to classify input images into \n",
    "# predefined categories or classes. For example, classifying images of animals into different species or identifying different \n",
    "# objects in a scene.\n",
    "\n",
    "# Object Detection: CNNs can be used for object detection tasks, where the goal is to detect and localize objects within an \n",
    "# image and classify them into predefined categories. This is commonly used in applications such as autonomous vehicles, \n",
    "# surveillance systems, and medical imaging.\n",
    "\n",
    "# Image Segmentation: CNNs can segment images into different regions or objects, where each pixel in the image is assigned a \n",
    "# class label. This is useful for tasks such as medical image analysis, semantic segmentation, and scene understanding.\n",
    "\n",
    "# Feature Extraction: CNNs are often used as feature extractors in conjunction with other machine learning algorithms. By \n",
    "# leveraging the learned representations from CNNs, features can be extracted from input images and used as input to classifiers \n",
    "# or other models for various tasks.\n",
    "\n",
    "# Image Generation: CNNs can also be used for generative tasks, where the goal is to generate new images that are similar to a \n",
    "# given dataset. This is commonly used in applications such as image synthesis, style transfer, and image enhancement.\n",
    "    \n",
    "# In the example below, we will focus on image classification, specifically we will loop through several images in a folder, \n",
    "# which has several sub-folders, each sub-folder having seperate classes of images, then train the model, and finally load one \n",
    "# image and get the model to classify that one image.\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "path_to_folder_with_subfolders = 'C:\\\\Users\\\\CNN\\\\Several Images\\\\'\n",
    " \n",
    "# Define parameters\n",
    "image_size = (128, 128)\n",
    "batch_size = 32\n",
    "num_classes = len(os.listdir(path_to_folder_with_subfolders))\n",
    "\n",
    "# Data preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Splitting the data into training and validation sets\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    path_to_folder_with_subfolders,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'  # Using the training subset of the data\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    path_to_folder_with_subfolders,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Using the validation subset of the data\n",
    ")\n",
    "\n",
    "# Define the CNN architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=5, validation_data=validation_generator)\n",
    "\n",
    "# Save the trained model\n",
    "# model.save('image_classification_model.h5')\n",
    "\n",
    "# Load the trained model\n",
    "# loaded_model = tf.keras.models.load_model('image_classification_model.h5')\n",
    "\n",
    "# Load and preprocess the single image for classification\n",
    "img_path = 'C:\\\\Users\\\\CNN\\\\image.jpg'\n",
    "img = tf.keras.preprocessing.image.load_img(img_path, target_size=image_size)\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Get class labels\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Print the predicted class\n",
    "print(\"Predicted class:\", class_labels[predicted_class])\n",
    "\n",
    "# Final Result:  \n",
    "# \"Predicted class: mouse\"\n",
    "\n",
    "# Yeah! The model looped through several sub-folders, each of which contained images of 'cat', 'dog', 'squirrel', 'giraffe' and 'mouse', \n",
    "# and it it corredctly predicted the the 'image.jpg' was indeed an image of a mouse!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72e8ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# Gated Recurrent Unit (GRU):\n",
    "\n",
    "# Gated Recurrent Units (GRUs) are a type of recurrent neural network (RNN) architecture that is commonly used for \n",
    "# various sequence modeling tasks. Here are some common types of analysis and tasks that can be performed using GRUs:\n",
    "\n",
    "#  Sequence Prediction:\n",
    "#  GRUs can be used for sequence prediction tasks, where the goal is to predict the next element in a sequence based on the previous elements. \n",
    "#  Examples include time series forecasting, stock price prediction, weather forecasting, and natural language processing tasks such as \n",
    "#  next-word prediction.\n",
    "\n",
    "#  Sequence Classification:\n",
    "#  GRUs can be applied to sequence classification tasks, where the goal is to classify an entire sequence into one or \n",
    "#  more categories. Examples include sentiment analysis of text data, activity recognition from sensor data, and speech recognition.\n",
    "\n",
    "#  Sequence Generation:\n",
    "#  GRUs can generate sequences of data, such as text, music, or images, based on learned patterns from training data.\n",
    "#  Examples include text generation, music composition, and image captioning.\n",
    "\n",
    "#  Sequence-to-Sequence Learning:\n",
    "#  GRUs can be used for sequence-to-sequence learning tasks, where an input sequence is mapped to an output sequence.\n",
    "#  Examples include machine translation, question answering, and chatbot systems.\n",
    "\n",
    "#  Temporal Pattern Recognition:\n",
    "#  GRUs can recognize temporal patterns in sequential data and learn long-term dependencies between elements in the sequence.\n",
    "#  Examples include gesture recognition in videos, anomaly detection in time-series data, and event detection in sensor data.\n",
    "\n",
    "#  Feature Learning:\n",
    "#  GRUs can automatically learn useful representations or features from sequential data, which can then be used as input for \n",
    "#  downstream machine learning tasks.\n",
    "#  Examples include feature extraction from time-series data, speech recognition features, and text embeddings for natural \n",
    "#  language processing tasks.\n",
    "\n",
    "#  Time-Series Analysis:\n",
    "#  GRUs can analyze and model time-series data to detect patterns, trends, and anomalies.\n",
    "#  Examples include financial market forecasting, medical signal analysis, and industrial process monitoring.\n",
    "\n",
    "\n",
    "# In the example below, we are using a Gated Recurrent Unit (GRU) for next word prediction and for generating text embeddings \n",
    "# for natural language processing (NLP) tasks.\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "\n",
    "# Sample text data\n",
    "text_data = [\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"The cat sat on the mat\",\n",
    "    \"We need to do grocery shopping\",\n",
    "    \"This is a very nice hotel\",\n",
    "    \"I love machine learning\"\n",
    "]\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences and labels\n",
    "input_sequences = []\n",
    "for line in text_data:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences for equal length\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Create predictors and labels\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "# One-hot encode the labels\n",
    "label = tf.keras.utils.to_categorical(label, num_classes=total_words)\n",
    "\n",
    "# Build the GRU model\n",
    "model = Sequential([\n",
    "    Embedding(total_words, 100, input_length=max_sequence_len - 1),\n",
    "    GRU(150),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(predictors, label, epochs=100, verbose=1)\n",
    "\n",
    "\n",
    "# Function to generate next word predictions\n",
    "def predict_next_word(seed_text, next_words):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list)[0]\n",
    "        predicted_index = np.argmax(predicted_probs)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Generate next word predictions\n",
    "print(predict_next_word(\"We need\", 3))\n",
    "\n",
    "\n",
    "# Final Result: \n",
    "# \"We need to do grocery\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e968716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################\n",
    "# Generative Adversarial Network (GAN):\n",
    "\n",
    "# Generative Adversarial Networks (GANs) are a class of deep learning models that are primarily used for generating new \n",
    "# data samples that are similar to a given dataset. GANs consist of two neural networks: a generator and a discriminator, \n",
    "# which are trained simultaneously in a competitive manner. While the primary application of GANs is data generation, they \n",
    "# can also be used for various other types of analysis and tasks. Here are some common types of analysis that can be performed \n",
    "# using Generative Adversarial Networks (GANs):\n",
    "\n",
    "#  Data Generation:\n",
    "#  GANs are most commonly used for generating new data samples that are similar to a given dataset. This can include generating \n",
    "#  realistic images, videos, audio, text, and other types of data.\n",
    "#  Example applications include generating synthetic images of faces, bedrooms, or other objects; generating realistic artwork \n",
    "#  or music; and generating realistic text or speech.\n",
    "\n",
    "#  Data Augmentation:\n",
    "#  GANs can be used to augment existing datasets by generating additional synthetic samples. This can help in increasing the \n",
    "#  diversity of the dataset and improving the performance of machine learning models trained on limited data.\n",
    "#  Example applications include generating additional images for training computer vision models and generating additional text \n",
    "#  samples for training natural language processing models.\n",
    "\n",
    "#  Style Transfer:\n",
    "#  GANs can be used for style transfer, where the style of one image or dataset is transferred to another image or dataset. This \n",
    "#  can be used for artistic purposes or for transferring the style of one domain to another.\n",
    "#  Example applications include transferring the style of one painting to another painting, transferring the style of one photograph \n",
    "#  to another photograph, and transferring the style of one type of music to another type of music.\n",
    "\n",
    "#  Anomaly Detection:\n",
    "#  GANs can be used for anomaly detection by training the discriminator on normal data samples and then using the generator to generate \n",
    "#  synthetic samples. Anomalies can be detected by measuring the difference between the generated samples and the real samples.\n",
    "#  Example applications include detecting anomalies in medical images, financial transactions, and network traffic.\n",
    "\n",
    "#  Domain Adaptation:\n",
    "#  GANs can be used for domain adaptation, where the goal is to transfer knowledge learned from one domain to another domain with \n",
    "#  different characteristics. This can help in improving the performance of machine learning models when there is a mismatch between \n",
    "#  the training and test data distributions.\n",
    "#  Example applications include adapting a model trained on synthetic data to real-world data, adapting a model trained on one type of \n",
    "#  sensor data to another type of sensor data, and adapting a model trained on one language to another language.\n",
    "\n",
    "#  Image-to-Image Translation:\n",
    "#  GANs can be used for image-to-image translation, where the goal is to translate an image from one domain to another domain while \n",
    "#  preserving important features such as content and style.\n",
    "#  Example applications include translating images from one artistic style to another, translating images from one domain to another \n",
    "#  (e.g., day to night, black and white to color), and translating images between different modalities (e.g., sketch to photograph, \n",
    "#  satellite image to map).\n",
    "        \n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "# Function to load and preprocess images from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = load_img(os.path.join(folder, filename), target_size=(64, 64))\n",
    "        img_array = img_to_array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load images from a folder\n",
    "image_folder = 'C:\\\\Users\\\\ryan_\\\\Desktop\\\\Briefcase\\\\PDFs\\\\1-ALL PYTHON & R CODE SAMPLES\\\\A - GITHUB\\\\Neural Networks - FNN vs CNN vs RNN vs GRU vs GAN\\\\CNN\\\\Several Images\\\\dog\\\\'\n",
    "X_train = load_images_from_folder(image_folder)\n",
    "\n",
    "# Generator model\n",
    "generator = Sequential([\n",
    "    Dense(8 * 8 * 256, input_dim=100, activation='relu'),\n",
    "    Reshape((8, 8, 256)),\n",
    "    Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', activation='relu'),\n",
    "    Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', activation='relu'),\n",
    "    Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Define a separate model for training the generator\n",
    "generator_input = Input(shape=(100,))\n",
    "generated_image = generator(generator_input)\n",
    "\n",
    "generator_model = Model(generator_input, generated_image)\n",
    "\n",
    "# Compile the generator model\n",
    "generator_model.compile(optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss='binary_crossentropy')\n",
    "\n",
    "# Generate noise as input to the generator\n",
    "noise = np.random.normal(0, 1, (len(X_train), 100))  # Generating noise samples for each image in the dataset\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 1000\n",
    "\n",
    "# Train the generator on noise\n",
    "generator_model.fit(noise, X_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Generate fake images after training\n",
    "fake_images = generator.predict(noise)\n",
    "\n",
    "# Display generated images\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(min(16, len(fake_images))):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(fake_images[i])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Final Result:\n",
    "\n",
    "# The GAN is essentially learning to mimic the distribution of the images it's trained on. If you only have three \n",
    "# images of dogs in your dataset, the GAN will learn to generate images that resemble those three images but won't \n",
    "# be able to create entirely new variations of dogs that it hasn't seen before.\n",
    "\n",
    "# To generate entirely new images of dogs that don't exist in your original dataset, you'd typically need a much \n",
    "# larger and diverse dataset. This would enable the GAN to learn a richer representation of the characteristics of \n",
    "# dogs and be able to generate novel variations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7357614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# END!!!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
