{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5783692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A short time ago I was tasked with organizing 1 million time series files in a data lake. I had to merge files that were\n",
    "# subbstantially similar, based on column names, into a specific dataframe, and if the CSV files were different, they had \n",
    "# to be merged into their own dataframes. Eventually, everything was pushed into a Synapse datbased (SQL Server), in Azure. \n",
    "# Why was Bloomberg changing the column names for it's bond data...I have no idea....but that's what we had to deal with.\n",
    "# The main challenge was to figure out which files were similar, or dissimilar, and then do all the appropriate merges. \n",
    "# At the time, the process was quite manual, tedious, and frustrating too. My team achieved the intended goal, and we \n",
    "# merged 1 million files into 250 tables in the database, but the process was quite painful! I was recently thinking of a \n",
    "# more elegant solution to handle this kind of problem. The solution that I came up with is described below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4719bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basically, what are the benefits to loading CSV files into dataframes and merging these dataframes together, based on \n",
    "# similarity of column names?\n",
    "\n",
    "# Simplified Analysis: When working with multiple datasets, especially those with similar but not identical column names, \n",
    "# merging based on similarity can simplify data analysis. It allows you to combine related information from different \n",
    "# sources without the need for extensive data cleaning or renaming.\n",
    "\n",
    "# Preservation of Data Structure: By merging dataframes with similar column names, you preserve the overall structure and \n",
    "# integrity of the data. This ensures that related information remains organized and accessible within a single dataframe.\n",
    "\n",
    "# Improved Data Consistency: Merging based on column name similarity can help ensure consistency across datasets. It reduces \n",
    "# the risk of discrepancies or errors that may arise from combining data with mismatched column names.\n",
    "\n",
    "# Efficient Data Integration: Instead of manually aligning column names or performing complex data transformations, merging \n",
    "# based on similarity streamlines the integration process. It saves time and effort, especially when dealing with large or \n",
    "# complex datasets.\n",
    "\n",
    "# Enhanced Insights: Merging similar datasets enables comprehensive analysis and provides a more complete picture of the \n",
    "# underlying data. It allows you to leverage information from multiple sources to gain deeper insights and make \n",
    "# critical informed decisions.\n",
    "\n",
    "# Scalability and Flexibility: This approach is scalable and flexible, allowing you to merge dataframes with varying \n",
    "# degrees of similarity. Whether the column names are nearly identical or exhibit some variation, you can adapt the \n",
    "# merging process to accommodate different scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9936204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   ID     Name  Age\n",
      "0   1    Alice   25\n",
      "1   2      Bob   30\n",
      "2   3  Charlie   35,    ID  Person  Age\n",
      "0   4   David   40\n",
      "1   5  Edward   45\n",
      "2   6   Fiona   50,    ID   FName     LName  Age\n",
      "0   7  George  Peterson   55\n",
      "1   8  Hannah     Smith   60\n",
      "2   9     Ian     Jones   65,    ID FullName  Years\n",
      "0  10     Jack     28\n",
      "1  11    Katie     33\n",
      "2  12      Leo     38,    ID    Name  Years\n",
      "0  13    Mona     43\n",
      "1  14    Nick     48\n",
      "2  15  Olivia     53,    ID FullName  Score\n",
      "0  16     Paul     58\n",
      "1  17    Quinn     63\n",
      "2  18   Rachel     68,    EmpID EmployeeName  Experience\n",
      "0     19        Steve           5\n",
      "1     20         Tina          10\n",
      "2     21          Uma          15,    EmpID    Name  WorkYears\n",
      "0     22  Victor         20\n",
      "1     23   Wendy         25\n",
      "2     24  Xander         30,    ID EmployeeName  Experience\n",
      "0  25         Yara          35\n",
      "1  26         Zack          40\n",
      "2  27          Amy          45]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's create generic sample dataframes; I don't have the original data that I worked with before and I'm not going to post anything \n",
    "# confidential, or protected intellectual property, anyway\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "# Create the dataframes\n",
    "df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35]})\n",
    "df2 = pd.DataFrame({'ID': [4, 5, 6], 'Person': ['David', 'Edward', 'Fiona'], 'Age': [40, 45, 50]})\n",
    "df3 = pd.DataFrame({'ID': [7, 8, 9], 'FName': ['George', 'Hannah', 'Ian'], 'LName': ['Peterson', 'Smith', 'Jones'], 'Age': [55, 60, 65]})\n",
    "df4 = pd.DataFrame({'ID': [10, 11, 12], 'FullName': ['Jack', 'Katie', 'Leo'], 'Years': [28, 33, 38]})\n",
    "df5 = pd.DataFrame({'ID': [13, 14, 15], 'Name': ['Mona', 'Nick', 'Olivia'], 'Years': [43, 48, 53]})\n",
    "df6 = pd.DataFrame({'ID': [16, 17, 18], 'FullName': ['Paul', 'Quinn', 'Rachel'], 'Score': [58, 63, 68]})\n",
    "df7 = pd.DataFrame({'EmpID': [19, 20, 21], 'EmployeeName': ['Steve', 'Tina', 'Uma'], 'Experience': [5, 10, 15]})\n",
    "df8 = pd.DataFrame({'EmpID': [22, 23, 24], 'Name': ['Victor', 'Wendy', 'Xander'], 'WorkYears': [20, 25, 30]})\n",
    "df9 = pd.DataFrame({'ID': [25, 26, 27], 'EmployeeName': ['Yara', 'Zack', 'Amy'], 'Experience': [35, 40, 45]})\n",
    "\n",
    "dataframes = [df1, df2, df3, df4, df5, df6, df7, df8, df9]\n",
    "print(dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b823411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.5        0.4        0.2        0.5        0.2\n",
      "  0.         0.2        0.2       ]\n",
      " [0.5        0.         0.4        0.2        0.2        0.2\n",
      "  0.         0.         0.2       ]\n",
      " [0.4        0.4        0.         0.16666667 0.16666667 0.16666667\n",
      "  0.         0.         0.16666667]\n",
      " [0.2        0.2        0.16666667 0.         0.5        0.5\n",
      "  0.         0.         0.2       ]\n",
      " [0.5        0.2        0.16666667 0.5        0.         0.2\n",
      "  0.         0.2        0.2       ]\n",
      " [0.2        0.2        0.16666667 0.5        0.2        0.\n",
      "  0.         0.         0.2       ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.2        0.5       ]\n",
      " [0.2        0.         0.         0.         0.2        0.\n",
      "  0.2        0.         0.        ]\n",
      " [0.2        0.2        0.16666667 0.2        0.2        0.2\n",
      "  0.5        0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to calculate Jaccard similarity between two sets\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return intersection / union\n",
    "\n",
    "# Calculate the Jaccard similarity for all pairs of dataframes\n",
    "def calculate_similarity_matrix(dataframes):\n",
    "    columns_list = [set(df.columns) for df in dataframes]\n",
    "    n = len(dataframes)\n",
    "    similarity_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for (i, cols1), (j, cols2) in combinations(enumerate(columns_list), 2):\n",
    "        sim = jaccard_similarity(cols1, cols2)\n",
    "        similarity_matrix[i, j] = sim\n",
    "        similarity_matrix[j, i] = sim\n",
    "    \n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "# Calculate similarity matrix\n",
    "similarity_matrix = calculate_similarity_matrix(dataframes)\n",
    "print(similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be2f01c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 1 2 2 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cluster the dataframes based on their similarity\n",
    "def cluster_dataframes(similarity_matrix, n_clusters):\n",
    "    # Convert the similarity matrix to a distance matrix\n",
    "    distance_matrix = 1 - similarity_matrix\n",
    "    \n",
    "    # Perform hierarchical clustering\n",
    "    Z = linkage(distance_matrix, 'complete')\n",
    "    \n",
    "    # Create clusters\n",
    "    labels = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Find 3 most similar groups of dataframes\n",
    "labels = cluster_dataframes(similarity_matrix, 3)\n",
    "print(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b995a0c-08c7-48ee-bf0d-d3589057e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group dataframes based on labels\n",
    "groups = {}\n",
    "for idx, label in enumerate(labels):\n",
    "    if label not in groups:\n",
    "        groups[label] = []\n",
    "    groups[label].append(dataframes[idx])\n",
    "\n",
    "# Function to merge dataframes\n",
    "def merge_dataframes(dfs):\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d9645dd-c29b-4f5c-aca5-f4d7047a8a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame 1:\n",
      "   ID     Name   Age FullName  Years\n",
      "0   1    Alice  25.0      NaN    NaN\n",
      "1   2      Bob  30.0      NaN    NaN\n",
      "2   3  Charlie  35.0      NaN    NaN\n",
      "3  10      NaN   NaN     Jack   28.0\n",
      "4  11      NaN   NaN    Katie   33.0\n",
      "5  12      NaN   NaN      Leo   38.0\n",
      "\n",
      "\n",
      "Merged DataFrame 2:\n",
      "      ID  Person   Age   FName     LName    Name  Years FullName  Score  \\\n",
      "0    4.0   David  40.0     NaN       NaN     NaN    NaN      NaN    NaN   \n",
      "1    5.0  Edward  45.0     NaN       NaN     NaN    NaN      NaN    NaN   \n",
      "2    6.0   Fiona  50.0     NaN       NaN     NaN    NaN      NaN    NaN   \n",
      "3    7.0     NaN  55.0  George  Peterson     NaN    NaN      NaN    NaN   \n",
      "4    8.0     NaN  60.0  Hannah     Smith     NaN    NaN      NaN    NaN   \n",
      "5    9.0     NaN  65.0     Ian     Jones     NaN    NaN      NaN    NaN   \n",
      "6   13.0     NaN   NaN     NaN       NaN    Mona   43.0      NaN    NaN   \n",
      "7   14.0     NaN   NaN     NaN       NaN    Nick   48.0      NaN    NaN   \n",
      "8   15.0     NaN   NaN     NaN       NaN  Olivia   53.0      NaN    NaN   \n",
      "9   16.0     NaN   NaN     NaN       NaN     NaN    NaN     Paul   58.0   \n",
      "10  17.0     NaN   NaN     NaN       NaN     NaN    NaN    Quinn   63.0   \n",
      "11  18.0     NaN   NaN     NaN       NaN     NaN    NaN   Rachel   68.0   \n",
      "12   NaN     NaN   NaN     NaN       NaN  Victor    NaN      NaN    NaN   \n",
      "13   NaN     NaN   NaN     NaN       NaN   Wendy    NaN      NaN    NaN   \n",
      "14   NaN     NaN   NaN     NaN       NaN  Xander    NaN      NaN    NaN   \n",
      "15  25.0     NaN   NaN     NaN       NaN     NaN    NaN      NaN    NaN   \n",
      "16  26.0     NaN   NaN     NaN       NaN     NaN    NaN      NaN    NaN   \n",
      "17  27.0     NaN   NaN     NaN       NaN     NaN    NaN      NaN    NaN   \n",
      "\n",
      "    EmpID  WorkYears EmployeeName  Experience  \n",
      "0     NaN        NaN          NaN         NaN  \n",
      "1     NaN        NaN          NaN         NaN  \n",
      "2     NaN        NaN          NaN         NaN  \n",
      "3     NaN        NaN          NaN         NaN  \n",
      "4     NaN        NaN          NaN         NaN  \n",
      "5     NaN        NaN          NaN         NaN  \n",
      "6     NaN        NaN          NaN         NaN  \n",
      "7     NaN        NaN          NaN         NaN  \n",
      "8     NaN        NaN          NaN         NaN  \n",
      "9     NaN        NaN          NaN         NaN  \n",
      "10    NaN        NaN          NaN         NaN  \n",
      "11    NaN        NaN          NaN         NaN  \n",
      "12   22.0       20.0          NaN         NaN  \n",
      "13   23.0       25.0          NaN         NaN  \n",
      "14   24.0       30.0          NaN         NaN  \n",
      "15    NaN        NaN         Yara        35.0  \n",
      "16    NaN        NaN         Zack        40.0  \n",
      "17    NaN        NaN          Amy        45.0  \n",
      "\n",
      "\n",
      "Merged DataFrame 3:\n",
      "   EmpID EmployeeName  Experience\n",
      "0     19        Steve           5\n",
      "1     20         Tina          10\n",
      "2     21          Uma          15\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge dataframes in each group\n",
    "merged_dfs = []\n",
    "\n",
    "for key, group in groups.items():\n",
    "    merged_df = merge_dataframes(group)\n",
    "    merged_dfs.append(merged_df)\n",
    "\n",
    "# Display merged dataframes\n",
    "for idx, merged_df in enumerate(merged_dfs):\n",
    "    print(f\"Merged DataFrame {idx + 1}:\")\n",
    "    print(merged_df)\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9f422-0ecf-41f3-b9f2-1168991365fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Jaccard Similarity is a measure used to compare the similarity and dissimilarity between two sets. It is commonly used \n",
    "# in data mining, information retrieval, and text analysis to quantify the similarity between two collections of objects.\n",
    "\n",
    "# This solution can simplify a complex process, and automate the tasks of something that is very manual and time consuming, \n",
    "# Anything that is a manual process will inevitably lead to wasted time and countless errors, which will propagate within \n",
    "# the environment for a long time to come.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd37b91c-bf63-412e-a234-10ae4ba248cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# END!!!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
